{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Jupyter modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dorasir\\anaconda3\\envs\\net-simu\\lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import pandas as pd\n",
    "from utils.transformation import clr_transform, alr_transform\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from utils import simulation\n",
    "import rpy2.robjects as robjects\n",
    "import seaborn as sns\n",
    "from utils.generalized_lotka_volterra import GeneralizedLotkaVolterra\n",
    "from utils.compositional_lotka_volterra import CompositionalLotkaVolterra\n",
    "from scipy.stats import ttest_rel\n",
    "import utils.evaluations as ev\n",
    "from utils.evaluations import correlation_score, precision_matrix_score, clv_score, glv_score, pcor_score, sparcc_score, speic_score, baseline_score\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "from utils.transformation import clr_transform, alr_transform\n",
    "\n",
    "# Make sure the working directory is correct\n",
    "os.chdir('d:\\\\microbial_network\\\\microbial_network_explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for evaluation\n",
    "def evaluation(adj, abundance, evaluation_func, metrics=average_precision_score, verbose=False):\n",
    "    scores = []\n",
    "    for func in evaluation_func:\n",
    "        scores.append([func._method, *func(abundance, adj, metrics=metrics, verbose=verbose)])\n",
    "    columns = ['Method']\n",
    "    columns.extend([metric.__name__ for metric in metrics] if isinstance(metrics, List) else [metrics.__name__])\n",
    "    scores_df = pd.DataFrame(scores, columns=columns)\n",
    "    return scores_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the parameters for the first simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "n_vertices = 10\n",
    "avg_degree = 2\n",
    "network_type = 'random'\n",
    "interaction_type = 'random'\n",
    "time_points = 1000\n",
    "time_step = 0.01\n",
    "downsample = 1\n",
    "noise_var = 1e-3\n",
    "\n",
    "evaluation_func = [correlation_score, precision_matrix_score, clv_score, glv_score, pcor_score, sparcc_score, speic_score, baseline_score]\n",
    "metrics = [average_precision_score, roc_auc_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# result_df = pd.DataFrame(columns=[\"Method\", \"run\", \"average_precision_score\", \"roc_auc_score\", \"abs_rel\"])\n",
    "# repeat = 50\n",
    "# # Setup the random seed generator\n",
    "# rng = np.random.default_rng(42)\n",
    "\n",
    "# for i in range(repeat):\n",
    "#     seed = rng.integers(0, 2**32 - 1)\n",
    "#     z, x, abd, adj, M = simulation.simulate_glv(\n",
    "#         num_taxa=n_vertices,\n",
    "#         avg_degree=avg_degree,\n",
    "#         time_points=time_points,\n",
    "#         time_step=time_step,\n",
    "#         downsample=1,\n",
    "#         noise_var=0,\n",
    "#         seed=seed,\n",
    "#     )\n",
    "#     score_df = evaluation(adj, z, evaluation_func, metrics=metrics, verbose=False)\n",
    "#     score_df[\"run\"] = i\n",
    "#     score_df[\"abs_rel\"] = \"Absolute\"\n",
    "#     result_df = result_df.append(score_df, ignore_index=True)\n",
    "\n",
    "#     score_df = evaluation(adj, abd, evaluation_func, metrics=metrics, verbose=False)\n",
    "#     score_df[\"run\"] = i\n",
    "#     score_df[\"abs_rel\"] = \"Relative\"\n",
    "#     result_df = result_df.append(score_df, ignore_index=True)\n",
    "# result_df.to_csv(\"data\\\\temp_results\\\\simulation_results.csv\", index=False)\n",
    "result_df = pd.read_csv(\"data\\\\temp_results\\\\simulation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mMethod\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maverage_precision_score\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mroc_auc_score\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m repeat \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Setup the random seed generator\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(columns=[\"Method\", \"run\", \"average_precision_score\", \"roc_auc_score\"])\n",
    "repeat = 50\n",
    "# Setup the random seed generator\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for i in range(repeat):\n",
    "    seed = rng.integers(0, 2**32 - 1)\n",
    "    z, x, abd, adj, M = simulation.simulate_noiseless_glv(\n",
    "        num_taxa=n_vertices,\n",
    "        avg_degree=avg_degree,\n",
    "        time_points=time_points,\n",
    "        downsample=1,\n",
    "        seed=seed,\n",
    "    )\n",
    "    score_df = evaluation(adj, z, evaluation_func, metrics=metrics, verbose=False)\n",
    "    score_df[\"run\"] = i\n",
    "    result_df = result_df.append(score_df, ignore_index=True)\n",
    "result_df.to_csv(\"data\\\\temp_results\\\\noiseless_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net-simu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbe25c87dd4947f7df6284cb2d993a284cf54cb5c7f845d17bcee5047f248a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
